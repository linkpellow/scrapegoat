# âœ… ScraperAPI Integration Complete

## What Was Implemented

### 1. API Key Usage Tracking System
- **Model:** `app/models/api_key_usage.py`
  - Tracks total credits, used credits, remaining credits
  - Automatic deactivation when credits exhausted
  - Last used timestamp tracking

- **Service:** `app/services/api_key_manager.py`
  - Register API keys with credit limits
  - Get available keys (auto-rotates when exhausted)
  - Record usage (tracks each API call)
  - Get usage statistics

### 2. ScraperAPI Integration
- **Extraction Function:** `app/workers/scraperapi_extract.py`
  - Full ScraperAPI integration
  - Supports single-page and list crawling
  - Automatic usage tracking (1 credit per request)
  - Error handling and fallback

### 3. Automatic Fallback Logic
- **Updated:** `app/workers/tasks.py`
  - Tries ScrapingBee first
  - Automatically falls back to ScraperAPI if ScrapingBee fails
  - Seamless transition - no user intervention needed

### 4. Configuration
- **Updated:** `app/config.py`
  - Support for multiple ScraperAPI keys
  - Environment variable parsing
  - Key retrieval methods

### 5. API Endpoints
- **New:** `app/api/api_keys.py`
  - `GET /api-keys/usage` - Check credit usage
  - `POST /api-keys/register` - Register new keys

### 6. Database Migration
- **Created:** `alembic/versions/f1a2b3c4d5e6_add_api_key_usage_tracking.py`
  - Creates `api_key_usage` table
  - Indexes for performance

### 7. Startup Initialization
- **Updated:** `app/main.py`
  - Auto-registers ScraperAPI keys on startup
  - Initializes credit tracking

---

## ğŸš€ Quick Setup on Railway

### Step 1: Set Environment Variable

**For a single key (recommended):**
```bash
railway variables set APP_SCRAPERAPI_KEY=4c5be84cded205410592f07e6a7e78dd
```

**âš ï¸ IMPORTANT:** Use `APP_SCRAPERAPI_KEY` (no "API" in the middle!)
- âœ… CORRECT: `APP_SCRAPERAPI_KEY`
- âŒ WRONG: `APP_SCRAPERAPI_API_KEY` (won't work!)

Or in Railway dashboard:
1. Go to your project: https://railway.com/project/fcaf308b-876f-477d-ac80-f0482eabff41
2. Click "Variables"
3. Add: `APP_SCRAPERAPI_KEY` = `4c5be84cded205410592f07e6a7e78dd`

**For multiple keys (comma-separated):**
```bash
railway variables set APP_SCRAPERAPI_API_KEYS=key1,key2,key3
```

### Step 2: Deploy

The migration will run automatically on next deploy, or trigger manually:

```bash
railway run alembic upgrade head
```

### Step 3: Verify

```bash
# Check API key is registered
curl https://scrapegoat-production.up.railway.app/api-keys/usage

# Should show:
# {
#   "success": true,
#   "keys": [{
#     "provider": "scraperapi",
#     "total_credits": 5000,
#     "used_credits": 0,
#     "remaining_credits": 5000,
#     "is_active": true
#   }]
# }
```

---

## ğŸ“Š Usage Tracking

### Check Credits Anytime

```bash
# All keys
curl https://scrapegoat-production.up.railway.app/api-keys/usage

# Just ScraperAPI
curl https://scrapegoat-production.up.railway.app/api-keys/usage?provider=scraperapi
```

### Response Shows:
- âœ… Total credits per key
- âœ… Used credits (exact count)
- âœ… Remaining credits (real-time)
- âœ… Active status
- âœ… Last used timestamp

---

## ğŸ”„ How It Works

### Escalation Flow

```
1. HTTP (FREE) â†’ Fast, works for simple sites
   â†“ Blocked/JS detected
2. Playwright (FREE) â†’ Handles JS, modals, basic blocks
   â†“ Captcha/hard block
3. ScrapingBee (PAID) â†’ Advanced bypass
   â†“ Out of credits (401) or fails
4. ScraperAPI (FREE - 5000 credits) â†’ Automatic fallback âœ…
```

### Credit Tracking

- **Each request = 1 credit**
- **Tracked immediately** after successful request
- **Database updated** in real-time
- **Key deactivated** automatically when credits = 0
- **Next available key** used automatically

---

## â• Adding More Keys

### Multiple Keys (Comma-Separated)

```bash
railway variables set APP_SCRAPERAPI_API_KEYS=key1,key2,key3
```

### Individual Keys

```bash
railway variables set APP_SCRAPERAPI_KEY_1=4c5be84cded205410592f07e6a7e78dd
railway variables set APP_SCRAPERAPI_KEY_2=another_key_here
```

### Via API

```bash
curl -X POST https://scrapegoat-production.up.railway.app/api-keys/register \
  -H "Content-Type: application/json" \
  -d '{
    "provider": "scraperapi",
    "api_key": "new_key_here",
    "total_credits": 5000
  }'
```

---

## âœ… Testing

### Test the Integration

```bash
# This will automatically use ScraperAPI if ScrapingBee fails
curl -X POST "https://scrapegoat-production.up.railway.app/skip-tracing/search/by-name?name=John+Smith&city=Denver&state=CO"

# Check usage after
curl https://scrapegoat-production.up.railway.app/api-keys/usage?provider=scraperapi
```

---

## ğŸ“‹ Files Created/Modified

### New Files
- âœ… `app/models/api_key_usage.py` - Usage tracking model
- âœ… `app/services/api_key_manager.py` - Key management service
- âœ… `app/workers/scraperapi_extract.py` - ScraperAPI extraction
- âœ… `app/api/api_keys.py` - Usage API endpoints
- âœ… `alembic/versions/f1a2b3c4d5e6_add_api_key_usage_tracking.py` - Migration
- âœ… `SCRAPERAPI_SETUP.md` - Setup guide
- âœ… `SCRAPERAPI_INTEGRATION_COMPLETE.md` - This file

### Modified Files
- âœ… `app/config.py` - Added ScraperAPI key support
- âœ… `app/workers/tasks.py` - Added ScraperAPI fallback
- âœ… `app/main.py` - Added startup key registration
- âœ… `app/models/__init__.py` - Added ApiKeyUsage export
- âœ… `alembic/env.py` - Added ApiKeyUsage to migrations

---

## ğŸ¯ Next Steps

1. **Set the API key on Railway:**
   ```bash
   railway variables set APP_SCRAPERAPI_API_KEYS=4c5be84cded205410592f07e6a7e78dd
   ```

2. **Deploy to Railway:**
   - Push to git (if using GitHub integration)
   - Or: `railway up`

3. **Verify it works:**
   ```bash
   curl https://scrapegoat-production.up.railway.app/api-keys/usage
   ```

4. **Test enrichment:**
   ```bash
   curl -X POST "https://scrapegoat-production.up.railway.app/skip-tracing/search/by-name?name=Test&city=Test&state=CA"
   ```

5. **Monitor usage:**
   - Check `/api-keys/usage` regularly
   - Watch Railway logs for ScraperAPI usage

---

## ğŸ“Š Expected Behavior

### When ScrapingBee Has Credits
- Uses ScrapingBee first
- Falls back to ScraperAPI only if ScrapingBee fails

### When ScrapingBee Out of Credits
- Automatically uses ScraperAPI
- Tracks usage: 1 credit per request
- Shows remaining: 4999, 4998, 4997...

### When ScraperAPI Credits Exhausted
- Key automatically deactivated
- System logs warning
- Falls back to free methods (HTTP/Playwright) or fails gracefully

---

## ğŸ‰ Summary

**You now have:**
- âœ… Free ScraperAPI integration (5000 credits)
- âœ… Automatic fallback from ScrapingBee
- âœ… Real-time usage tracking
- âœ… Multiple key support
- âœ… Credit monitoring API

**Your system will automatically use ScraperAPI when ScrapingBee fails!**

Just set the environment variable on Railway and you're good to go! ğŸš€
